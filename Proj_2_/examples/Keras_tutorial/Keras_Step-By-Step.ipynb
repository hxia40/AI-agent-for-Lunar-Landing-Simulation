{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "# Your First Deep Learning Project in Python with Keras Step-By-Step\n",
    "\n",
    "by Jason Brownlee on July 24, 2019 in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a powerful and easy-to-use free open source Python library for developing and evaluating deep learning models.\n",
    "\n",
    "It wraps the efficient numerical computation libraries Theano and TensorFlow and allows you to define and train neural network models in just a few lines of code.\n",
    "\n",
    "In this tutorial, you will discover how to create your first deep learning neural network model in Python using Keras.\n",
    "\n",
    "Discover how to develop deep learning models for a range of predictive modeling problems with just a few lines of code in my new book, with 18 step-by-step tutorials and 9 projects.\n",
    "\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tutorial Overview\n",
    "\n",
    "There is not a lot of code required, but we are going to step over it slowly so that you will know how to create your own models in the future.\n",
    "\n",
    "The steps you are going to cover in this tutorial are as follows:\n",
    "\n",
    "Load Data.\n",
    "\n",
    "Define Keras Model.\n",
    "\n",
    "Compile Keras Model.\n",
    "\n",
    "Fit Keras Model.\n",
    "\n",
    "Evaluate Keras Model.\n",
    "\n",
    "Tie It All Together.\n",
    "\n",
    "Make Predictions\n",
    "\n",
    "\n",
    "This Keras tutorial has a few requirements:\n",
    "\n",
    "You have Python 2 or 3 installed and configured.\n",
    "You have SciPy (including NumPy) installed and configured.\n",
    "You have Keras and a backend (Theano or TensorFlow) installed and configured.\n",
    "If you need help with your environment, see the tutorial:\n",
    "\n",
    "How to Setup a Python Environment for Deep Learning\n",
    "\n",
    "Create a new file called keras_first_network.py and type or copy-and-paste the code into the file as you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Data\n",
    "\n",
    "The first step is to define the functions and classes we intend to use in this tutorial.\n",
    "\n",
    "We will use the NumPy library to load our dataset and we will use two classes from the Keras library to define our model.\n",
    "\n",
    "The imports required are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load our dataset.\n",
    "\n",
    "In this Keras tutorial, we are going to use the Pima Indians onset of diabetes dataset. This is a standard machine learning dataset from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years.\n",
    "\n",
    "As such, it is a binary classification problem (onset of diabetes as 1 or not as 0). All of the input variables that describe each patient are numerical. This makes it easy to use directly with neural networks that expect numerical input and output values, and ideal for our first neural network in Keras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the file as a matrix of numbers using the NumPy function loadtxt().\n",
    "\n",
    "There are eight input variables and one output variable (the last column). We will be learning a model to map rows of input variables (X) to an output variable (y), which we often summarize as y = f(X).\n",
    "\n",
    "The variables can be summarized as follows:\n",
    "\n",
    "Input Variables (X):\n",
    "\n",
    "Number of times pregnant; Plasma glucose concentration a 2 hours in an oral glucose tolerance test; Diastolic blood pressure (mm Hg); Triceps skin fold thickness (mm); 2-Hour serum insulin (mu U/ml); Body mass index (weight in kg/(height in m)^2); Diabetes pedigree function; Age (years); Output Variables (y):\n",
    "\n",
    "Class variable (0 or 1)\n",
    "Once the CSV file is loaded into memory, we can split the columns of data into input and output variables.\n",
    "\n",
    "The data will be stored in a 2D array where the first dimension is rows and the second dimension is columns, e.g. [rows, columns].\n",
    "\n",
    "We can split the array into two arrays by selecting subsets of columns using the standard NumPy slice operator or “:” We can select the first 8 columns from index 0 to index 7 via the slice 0:8. We can then select the output column (the 9th variable) via index 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define our neural network model.\n",
    "\n",
    "Note, the dataset has 9 columns and the range 0:8 will select columns from 0 to 7, stopping before index 8. If this is new to you, then you can learn more about array slicing and ranges in this post:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define Keras Model\n",
    "\n",
    "Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "We create a Sequential model and add layers one at a time until we are happy with our network architecture.\n",
    "\n",
    "The first thing to get right is to ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument and setting it to 8 for the 8 input variables.\n",
    "\n",
    "How do we know the number of layers and their types?\n",
    "\n",
    "This is a very hard question. There are heuristics that we can use and often the best network structure is found through a process of trial and error experimentation (I explain more about this here). Generally, you need a network large enough to capture the structure of the problem.\n",
    "\n",
    "In this example, we will use a fully-connected network structure with three layers.\n",
    "\n",
    "Fully connected layers are defined using the Dense class. We can specify the number of neurons or nodes in the layer as the first argument, and specify the activation function using the activation argument.\n",
    "\n",
    "We will use the rectified linear unit activation function referred to as ReLU on the first two layers and the Sigmoid function in the output layer.\n",
    "\n",
    "It used to be the case that Sigmoid and Tanh activation functions were preferred for all layers. These days, better performance is achieved using the ReLU activation function. We use a sigmoid on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5.\n",
    "\n",
    "We can piece it all together by adding each layer:\n",
    "\n",
    "=> The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
    "\n",
    "=> The first hidden layer has 12 nodes and uses the relu activation function.\n",
    "\n",
    "=> The second hidden layer has 8 nodes and uses the relu activation function.\n",
    "\n",
    "=> The output layer has one node and uses the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the most confusing thing here is that the shape of the input to the model lis defined as an argument on the first hidden layer. This means that the line of code that adds the first Dense layer is doing 2 things, defining the input or visible layer and the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compile Keras Model\n",
    "\n",
    "Now that the model is defined, we can compile it.\n",
    "\n",
    "Compiling the model uses the efficient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow. The backend automatically chooses the best way to represent the network for training and making predictions to run on your hardware, such as CPU or GPU or even distributed.\n",
    "\n",
    "When compiling, we must specify some additional properties required when training the network. Remember training a network means finding the best set of weights to map inputs to outputs in our dataset.\n",
    "\n",
    "We must specify the loss function to use to evaluate a set of weights, the optimizer is used to search through different weights for the network and any optional metrics we would like to collect and report during training.\n",
    "\n",
    "In this case, we will use cross entropy as the loss argument. This loss is for a binary classification problems and is defined in Keras as “binary_crossentropy“. You can learn more about choosing loss functions based on your problem here:\n",
    "\n",
    "How to Choose Loss Functions When Training Deep Learning Neural Networks\n",
    "We will define the optimizer as the efficient stochastic gradient descent algorithm “adam“. This is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems. To learn more about the Adam version of stochastic gradient descent see the post:\n",
    "\n",
    "Gentle Introduction to the Adam Optimization Algorithm for Deep Learning\n",
    "Finally, because it is a classification problem, we will collect and report the classification accuracy, defined via the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
